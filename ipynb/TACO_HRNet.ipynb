{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TACO-HRNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdA1y4RLo2cA"
      },
      "source": [
        "### **1. Installing TACO/HRNet dependencies**\n",
        "\n",
        "*observation:* to make sure that they were satisfied, run twice!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_l-wYM1qu88",
        "outputId": "5651765f-2826-4b90-9313-b4110a1eb0f9"
      },
      "source": [
        "!pip3 install --upgrade pip\n",
        "!pip3 install setuptools\n",
        "!pip3 install imgaug==0.4.0\n",
        "!pip3 install EasyDict==1.7\n",
        "!pip3 install opencv-python==3.4.2.17\n",
        "!pip3 install shapely==1.6.4\n",
        "!pip3 install Cython\n",
        "!pip3 install scipy\n",
        "!pip3 install pandas\n",
        "!pip3 install pyyaml\n",
        "!pip3 install json_tricks\n",
        "!pip3 install scikit-image\n",
        "!pip3 install yacs>=0.1.5\n",
        "!pip3 install tensorboardX>=1.6\n",
        "!pip3 install tqdm\n",
        "!pip3 install ninja\n",
        "!pip3 install PyDrive"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (20.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (51.1.2)\n",
            "Requirement already satisfied: imgaug==0.4.0 in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.6/dist-packages (from imgaug==0.4.0) (0.16.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from imgaug==0.4.0) (2.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug==0.4.0) (3.2.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug==0.4.0) (1.6.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from imgaug==0.4.0) (7.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug==0.4.0) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug==0.4.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from imgaug==0.4.0) (1.19.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from imgaug==0.4.0) (3.4.2.17)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2->imgaug==0.4.0) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2->imgaug==0.4.0) (2.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.4.0) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.4.0) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.4.0) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.4.0) (1.3.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.14.2->imgaug==0.4.0) (4.4.2)\n",
            "Requirement already satisfied: EasyDict==1.7 in /usr/local/lib/python3.6/dist-packages (1.7)\n",
            "Requirement already satisfied: opencv-python==3.4.2.17 in /usr/local/lib/python3.6/dist-packages (3.4.2.17)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python==3.4.2.17) (1.19.5)\n",
            "Requirement already satisfied: shapely==1.6.4 in /usr/local/lib/python3.6/dist-packages (1.6.4)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.21)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Requirement already satisfied: json_tricks in /usr/local/lib/python3.6/dist-packages (3.15.5)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (0.16.2)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.1.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (7.0.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio>=2.3.0->scikit-image) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.6/dist-packages (1.10.0.post2)\n",
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.12)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.17.2)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.15.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.17.4)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (4.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (4.6)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (51.1.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTueAySKprOb"
      },
      "source": [
        "### **2. Downloading TACO and splitting the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0e1h0jrtPjz",
        "outputId": "167e906a-c42d-4fc5-c5e4-2dcabdb66d97"
      },
      "source": [
        "!git clone https://github.com/pedropro/TACO.git /TACO/\n",
        "%cd /TACO/\n",
        "!python3 download.py\n",
        "!cd /TACO/detector && python3 split_dataset.py --dataset_dir ../data/\n",
        "%cd /content/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '/TACO'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 305 (delta 22), reused 21 (delta 10), pack-reused 270\u001b[K\n",
            "Receiving objects: 100% (305/305), 59.46 MiB | 35.88 MiB/s, done.\n",
            "Resolving deltas: 100% (173/173), done.\n",
            "/TACO\n",
            "Note. If for any reason the connection is broken. Just call me again and I will start where I left.\n",
            "Finished\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO2HUvRPyMwT"
      },
      "source": [
        "### **3. Downloading HRNet Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djN1VPxzu7Qo",
        "outputId": "41cd60dd-2fd7-465a-a6ee-080443a24699"
      },
      "source": [
        "!rm -rf HRNet\n",
        "!git clone https://github.com/jcfaracco/HRNet-Semantic-Segmentation.git -b pytorch-v1.1.1 HRNet"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'HRNet'...\n",
            "remote: Enumerating objects: 110, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/110)\u001b[K\rremote: Counting objects:   1% (2/110)\u001b[K\rremote: Counting objects:   2% (3/110)\u001b[K\rremote: Counting objects:   3% (4/110)\u001b[K\rremote: Counting objects:   4% (5/110)\u001b[K\rremote: Counting objects:   5% (6/110)\u001b[K\rremote: Counting objects:   6% (7/110)\u001b[K\rremote: Counting objects:   7% (8/110)\u001b[K\rremote: Counting objects:   8% (9/110)\u001b[K\rremote: Counting objects:   9% (10/110)\u001b[K\rremote: Counting objects:  10% (11/110)\u001b[K\rremote: Counting objects:  11% (13/110)\u001b[K\rremote: Counting objects:  12% (14/110)\u001b[K\rremote: Counting objects:  13% (15/110)\u001b[K\rremote: Counting objects:  14% (16/110)\u001b[K\rremote: Counting objects:  15% (17/110)\u001b[K\rremote: Counting objects:  16% (18/110)\u001b[K\rremote: Counting objects:  17% (19/110)\u001b[K\rremote: Counting objects:  18% (20/110)\u001b[K\rremote: Counting objects:  19% (21/110)\u001b[K\rremote: Counting objects:  20% (22/110)\u001b[K\rremote: Counting objects:  21% (24/110)\u001b[K\rremote: Counting objects:  22% (25/110)\u001b[K\rremote: Counting objects:  23% (26/110)\u001b[K\rremote: Counting objects:  24% (27/110)\u001b[K\rremote: Counting objects:  25% (28/110)\u001b[K\rremote: Counting objects:  26% (29/110)\u001b[K\rremote: Counting objects:  27% (30/110)\u001b[K\rremote: Counting objects:  28% (31/110)\u001b[K\rremote: Counting objects:  29% (32/110)\u001b[K\rremote: Counting objects:  30% (33/110)\u001b[K\rremote: Counting objects:  31% (35/110)\u001b[K\rremote: Counting objects:  32% (36/110)\u001b[K\rremote: Counting objects:  33% (37/110)\u001b[K\rremote: Counting objects:  34% (38/110)\u001b[K\rremote: Counting objects:  35% (39/110)\u001b[K\rremote: Counting objects:  36% (40/110)\u001b[K\rremote: Counting objects:  37% (41/110)\u001b[K\rremote: Counting objects:  38% (42/110)\u001b[K\rremote: Counting objects:  39% (43/110)\u001b[K\rremote: Counting objects:  40% (44/110)\u001b[K\rremote: Counting objects:  41% (46/110)\u001b[K\rremote: Counting objects:  42% (47/110)\u001b[K\rremote: Counting objects:  43% (48/110)\u001b[K\rremote: Counting objects:  44% (49/110)\u001b[K\rremote: Counting objects:  45% (50/110)\u001b[K\rremote: Counting objects:  46% (51/110)\u001b[K\rremote: Counting objects:  47% (52/110)\u001b[K\rremote: Counting objects:  48% (53/110)\u001b[K\rremote: Counting objects:  49% (54/110)\u001b[K\rremote: Counting objects:  50% (55/110)\u001b[K\rremote: Counting objects:  51% (57/110)\u001b[K\rremote: Counting objects:  52% (58/110)\u001b[K\rremote: Counting objects:  53% (59/110)\u001b[K\rremote: Counting objects:  54% (60/110)\u001b[K\rremote: Counting objects:  55% (61/110)\u001b[K\rremote: Counting objects:  56% (62/110)\u001b[K\rremote: Counting objects:  57% (63/110)\u001b[K\rremote: Counting objects:  58% (64/110)\u001b[K\rremote: Counting objects:  59% (65/110)\u001b[K\rremote: Counting objects:  60% (66/110)\u001b[K\rremote: Counting objects:  61% (68/110)\u001b[K\rremote: Counting objects:  62% (69/110)\u001b[K\rremote: Counting objects:  63% (70/110)\u001b[K\rremote: Counting objects:  64% (71/110)\u001b[K\rremote: Counting objects:  65% (72/110)\u001b[K\rremote: Counting objects:  66% (73/110)\u001b[K\rremote: Counting objects:  67% (74/110)\u001b[K\rremote: Counting objects:  68% (75/110)\u001b[K\rremote: Counting objects:  69% (76/110)\u001b[K\rremote: Counting objects:  70% (77/110)\u001b[K\rremote: Counting objects:  71% (79/110)\u001b[K\rremote: Counting objects:  72% (80/110)\u001b[K\rremote: Counting objects:  73% (81/110)\u001b[K\rremote: Counting objects:  74% (82/110)\u001b[K\rremote: Counting objects:  75% (83/110)\u001b[K\rremote: Counting objects:  76% (84/110)\u001b[K\rremote: Counting objects:  77% (85/110)\u001b[K\rremote: Counting objects:  78% (86/110)\u001b[K\rremote: Counting objects:  79% (87/110)\u001b[K\rremote: Counting objects:  80% (88/110)\u001b[K\rremote: Counting objects:  81% (90/110)\u001b[K\rremote: Counting objects:  82% (91/110)\u001b[K\rremote: Counting objects:  83% (92/110)\u001b[K\rremote: Counting objects:  84% (93/110)\u001b[K\rremote: Counting objects:  85% (94/110)\u001b[K\rremote: Counting objects:  86% (95/110)\u001b[K\rremote: Counting objects:  87% (96/110)\u001b[K\rremote: Counting objects:  88% (97/110)\u001b[K\rremote: Counting objects:  89% (98/110)\u001b[K\rremote: Counting objects:  90% (99/110)\u001b[K\rremote: Counting objects:  91% (101/110)\u001b[K\rremote: Counting objects:  92% (102/110)\u001b[K\rremote: Counting objects:  93% (103/110)\u001b[K\rremote: Counting objects:  94% (104/110)\u001b[K\rremote: Counting objects:  95% (105/110)\u001b[K\rremote: Counting objects:  96% (106/110)\u001b[K\rremote: Counting objects:  97% (107/110)\u001b[K\rremote: Counting objects:  98% (108/110)\u001b[K\rremote: Counting objects:  99% (109/110)\u001b[K\rremote: Counting objects: 100% (110/110)\u001b[K\rremote: Counting objects: 100% (110/110), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 1328 (delta 65), reused 71 (delta 39), pack-reused 1218\u001b[K\n",
            "Receiving objects: 100% (1328/1328), 1.27 MiB | 17.34 MiB/s, done.\n",
            "Resolving deltas: 100% (823/823), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCsJSYAsyVZJ"
      },
      "source": [
        "### **4. Executing HRNet Training with TACO**\n",
        "\n",
        "*Observation:* this is a demonstration. The number of epochs are not enough to train the HRNet architecture. User another train YAML to train and evaulate your net. If you use the examples, it can take more than 9 hours to train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9G7yQju4SPX",
        "outputId": "2e395ca1-51c4-41b7-9652-3efe0bc8b76b"
      },
      "source": [
        "%cd /content/HRNet\n",
        "# This is only a demo. To train better HR-Net, use 200 epochs or more (it takes long hours to finish).\n",
        "!python3 -m torch.distributed.launch tools/train.py --cfg experiments/taco/seg_hrnet_w18_small_cls5_720x720_sgd_lr4e-3_wd1e-4_bs_16_epoch10_demo.yaml OUTPUT_DIR output1.6.0\n",
        "%cd .."
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/HRNet\n",
            "=> creating output1.6.0/taco/seg_hrnet_w18_small_cls5_720x720_sgd_lr4e-3_wd1e-4_bs_16_epoch10_demo\n",
            "=> creating log/taco/seg_hrnet/seg_hrnet_w18_small_cls5_720x720_sgd_lr4e-3_wd1e-4_bs_16_epoch10_demo_2021-01-20-19-49\n",
            "Namespace(cfg='experiments/taco/seg_hrnet_w18_small_cls5_720x720_sgd_lr4e-3_wd1e-4_bs_16_epoch10_demo.yaml', local_rank=0, opts=['OUTPUT_DIR', 'output1.6.0'])\n",
            "AUTO_RESUME: False\n",
            "CUDNN:\n",
            "  BENCHMARK: True\n",
            "  DETERMINISTIC: False\n",
            "  ENABLED: True\n",
            "DATASET:\n",
            "  DATASET: taco\n",
            "  EXTRA_TRAIN_SET: \n",
            "  NUM_CLASSES: 5\n",
            "  ROOT: /TACO/data/\n",
            "  TEST_SET: val\n",
            "  TRAIN_SET: train\n",
            "DEBUG:\n",
            "  DEBUG: False\n",
            "  SAVE_BATCH_IMAGES_GT: False\n",
            "  SAVE_BATCH_IMAGES_PRED: False\n",
            "  SAVE_HEATMAPS_GT: False\n",
            "  SAVE_HEATMAPS_PRED: False\n",
            "GPUS: (0, 1, 2, 3)\n",
            "LOG_DIR: log\n",
            "LOSS:\n",
            "  CLASS_BALANCE: True\n",
            "  OHEMKEEP: 131072\n",
            "  OHEMTHRES: 0.9\n",
            "  USE_OHEM: False\n",
            "MODEL:\n",
            "  EXTRA:\n",
            "    FINAL_CONV_KERNEL: 1\n",
            "    STAGE1:\n",
            "      BLOCK: BOTTLENECK\n",
            "      FUSE_METHOD: SUM\n",
            "      NUM_BLOCKS: [2]\n",
            "      NUM_CHANNELS: [64]\n",
            "      NUM_MODULES: 1\n",
            "      NUM_RANCHES: 1\n",
            "    STAGE2:\n",
            "      BLOCK: BASIC\n",
            "      FUSE_METHOD: SUM\n",
            "      NUM_BLOCKS: [2, 2]\n",
            "      NUM_BRANCHES: 2\n",
            "      NUM_CHANNELS: [18, 36]\n",
            "      NUM_MODULES: 1\n",
            "    STAGE3:\n",
            "      BLOCK: BASIC\n",
            "      FUSE_METHOD: SUM\n",
            "      NUM_BLOCKS: [2, 2, 2]\n",
            "      NUM_BRANCHES: 3\n",
            "      NUM_CHANNELS: [18, 36, 72]\n",
            "      NUM_MODULES: 3\n",
            "    STAGE4:\n",
            "      BLOCK: BASIC\n",
            "      FUSE_METHOD: SUM\n",
            "      NUM_BLOCKS: [2, 2, 2, 2]\n",
            "      NUM_BRANCHES: 4\n",
            "      NUM_CHANNELS: [18, 36, 72, 144]\n",
            "      NUM_MODULES: 2\n",
            "  NAME: seg_hrnet\n",
            "  PRETRAINED: pretrained_models/hrnet_w18_small_model_v2.pth\n",
            "OUTPUT_DIR: output1.6.0\n",
            "PIN_MEMORY: True\n",
            "PRINT_FREQ: 50\n",
            "RANK: 0\n",
            "TEST:\n",
            "  BASE_SIZE: 1080\n",
            "  BATCH_SIZE_PER_GPU: 4\n",
            "  CENTER_CROP_TEST: False\n",
            "  FLIP_TEST: False\n",
            "  IMAGE_SIZE: [720, 720]\n",
            "  MODEL_FILE: \n",
            "  MULTI_SCALE: False\n",
            "  NUM_SAMPLES: 0\n",
            "  SCALE_LIST: [1]\n",
            "TRAIN:\n",
            "  BASE_SIZE: 1080\n",
            "  BATCH_SIZE_PER_GPU: 4\n",
            "  BEGIN_EPOCH: 0\n",
            "  DOWNSAMPLERATE: 1\n",
            "  END_EPOCH: 10\n",
            "  EXTRA_EPOCH: 0\n",
            "  EXTRA_LR: 0.001\n",
            "  FLIP: True\n",
            "  IGNORE_LABEL: -1\n",
            "  IMAGE_SIZE: [720, 720]\n",
            "  LR: 0.004\n",
            "  LR_FACTOR: 0.1\n",
            "  LR_STEP: [90, 110]\n",
            "  MOMENTUM: 0.9\n",
            "  MULTI_SCALE: True\n",
            "  NESTEROV: False\n",
            "  NUM_SAMPLES: 0\n",
            "  OPTIMIZER: sgd\n",
            "  RESUME: False\n",
            "  SCALE_FACTOR: 16\n",
            "  SHUFFLE: True\n",
            "  WD: 0.0001\n",
            "WORKERS: 4\n",
            "=> init weights from normal distribution\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "\n",
            "Total Parameters: 3,935,785\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "Total Multiply Adds (For Convolution and Linear Layers only): 17.620910458266735 GFLOPs\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "Number of Layers\n",
            "Conv2d : 146 layers   BatchNorm2d : 145 layers   ReLU : 119 layers   Bottleneck : 2 layers   BasicBlock : 38 layers   HighResolutionModule : 6 layers   \n",
            "loading annotations into memory...\n",
            "Done (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Epoch: [0/10] Iter:[0/75], Time: 8.10, lr: 0.004000, Loss: 1.567782\n",
            "Reducer buckets have been rebuilt in this iteration.\n",
            "mask label shape mismatch (4000, 1824) (3264, 2448)\n",
            "Epoch: [0/10] Iter:[50/75], Time: 1.89, lr: 0.003759, Loss: 0.491721\n",
            "Epoch: [0/10] Iter:[100/75], Time: 1.92, lr: 0.003517, Loss: 0.424259\n",
            "Epoch: [0/10] Iter:[150/75], Time: 1.86, lr: 0.003272, Loss: 0.399123\n",
            "Epoch: [0/10] Iter:[200/75], Time: 1.90, lr: 0.003026, Loss: 0.386450\n",
            "Epoch: [0/10] Iter:[250/75], Time: 1.89, lr: 0.002777, Loss: 0.370135\n",
            "=> saving checkpoint to output1.6.0/taco/seg_hrnet_w18_small_cls5_720x720_sgd_lr4e-3_wd1e-4_bs_16_epoch10_democheckpoint.pth.tar\n",
            "Loss: 0.242, MeanIU:  0.1906, Best_mIoU:  0.1906\n",
            "[0.95319842 0.         0.         0.         0.        ]\n",
            "Epoch: [1/10] Iter:[0/75], Time: 8.03, lr: 0.003638, Loss: 0.182257\n",
            "Epoch: [1/10] Iter:[50/75], Time: 1.96, lr: 0.003395, Loss: 0.305015\n",
            "Epoch: [1/10] Iter:[100/75], Time: 2.03, lr: 0.003149, Loss: 0.315985\n",
            "mask label shape mismatch (4000, 1824) (3264, 2448)\n",
            "Epoch: [1/10] Iter:[150/75], Time: 1.92, lr: 0.002902, Loss: 0.319993\n",
            "Epoch: [1/10] Iter:[200/75], Time: 1.91, lr: 0.002652, Loss: 0.321797\n",
            "Epoch: [1/10] Iter:[250/75], Time: 1.92, lr: 0.002399, Loss: 0.330010\n",
            "=> saving checkpoint to output1.6.0/taco/seg_hrnet_w18_small_cls5_720x720_sgd_lr4e-3_wd1e-4_bs_16_epoch10_democheckpoint.pth.tar\n",
            "Loss: 0.220, MeanIU:  0.1906, Best_mIoU:  0.1906\n",
            "[0.95319842 0.         0.         0.         0.        ]\n",
            "Epoch: [2/10] Iter:[0/75], Time: 6.55, lr: 0.003272, Loss: 0.164490\n",
            "mask label shape mismatch (4000, 1824) (3264, 2448)\n",
            "Epoch: [2/10] Iter:[50/75], Time: 2.03, lr: 0.003026, Loss: 0.293264\n",
            "Epoch: [2/10] Iter:[100/75], Time: 1.99, lr: 0.002777, Loss: 0.337729\n",
            "Epoch: [2/10] Iter:[150/75], Time: 2.02, lr: 0.002526, Loss: 0.335656\n",
            "Epoch: [2/10] Iter:[200/75], Time: 1.98, lr: 0.002272, Loss: 0.326059\n",
            "Epoch: [2/10] Iter:[250/75], Time: 1.98, lr: 0.002014, Loss: 0.322077\n",
            "=> saving checkpoint to output1.6.0/taco/seg_hrnet_w18_small_cls5_720x720_sgd_lr4e-3_wd1e-4_bs_16_epoch10_democheckpoint.pth.tar\n",
            "Loss: 0.225, MeanIU:  0.1909, Best_mIoU:  0.1909\n",
            "[9.53697877e-01 0.00000000e+00 9.37210604e-04 0.00000000e+00\n",
            " 0.00000000e+00]\n",
            "Epoch: [3/10] Iter:[0/75], Time: 6.83, lr: 0.002902, Loss: 0.333860\n",
            "Epoch: [3/10] Iter:[50/75], Time: 2.08, lr: 0.002652, Loss: 0.258104\n",
            "Epoch: [3/10] Iter:[100/75], Time: 2.02, lr: 0.002399, Loss: 0.308978\n",
            "Epoch: [3/10] Iter:[150/75], Time: 1.98, lr: 0.002144, Loss: 0.319207\n",
            "Epoch: [3/10] Iter:[200/75], Time: 1.99, lr: 0.001885, Loss: 0.314860\n",
            "Epoch: [3/10] Iter:[250/75], Time: 1.95, lr: 0.001621, Loss: 0.312339\n",
            "mask label shape mismatch (4000, 1824) (3264, 2448)\n",
            "=> saving checkpoint to output1.6.0/taco/seg_hrnet_w18_small_cls5_720x720_sgd_lr4e-3_wd1e-4_bs_16_epoch10_democheckpoint.pth.tar\n",
            "Loss: 0.241, MeanIU:  0.1904, Best_mIoU:  0.1909\n",
            "[0.95048144 0.         0.00143744 0.         0.        ]\n",
            "Epoch: [4/10] Iter:[0/75], Time: 7.88, lr: 0.002526, Loss: 0.227306\n",
            "Epoch: [4/10] Iter:[50/75], Time: 1.99, lr: 0.002272, Loss: 0.302931\n",
            "Epoch: [4/10] Iter:[100/75], Time: 1.94, lr: 0.002014, Loss: 0.334890\n",
            "Epoch: [4/10] Iter:[150/75], Time: 1.92, lr: 0.001754, Loss: 0.321067\n",
            "Epoch: [4/10] Iter:[200/75], Time: 1.96, lr: 0.001488, Loss: 0.316090\n",
            "mask label shape mismatch (4000, 1824) (3264, 2448)\n",
            "Epoch: [4/10] Iter:[250/75], Time: 1.97, lr: 0.001217, Loss: 0.307164\n",
            "=> saving checkpoint to output1.6.0/taco/seg_hrnet_w18_small_cls5_720x720_sgd_lr4e-3_wd1e-4_bs_16_epoch10_democheckpoint.pth.tar\n",
            "Loss: 0.215, MeanIU:  0.1907, Best_mIoU:  0.1909\n",
            "[0.9533448 0.        0.        0.        0.       ]\n",
            "Epoch: [5/10] Iter:[0/75], Time: 6.18, lr: 0.002144, Loss: 0.093722\n",
            "Epoch: [5/10] Iter:[50/75], Time: 2.19, lr: 0.001885, Loss: 0.281999\n",
            "Epoch: [5/10] Iter:[100/75], Time: 2.07, lr: 0.001621, Loss: 0.301423\n",
            "Epoch: [5/10] Iter:[150/75], Time: 1.96, lr: 0.001354, Loss: 0.317933\n",
            "Epoch: [5/10] Iter:[200/75], Time: 1.97, lr: 0.001080, Loss: 0.311233\n",
            "Epoch: [5/10] Iter:[250/75], Time: 1.97, lr: 0.000797, Loss: 0.305190\n",
            "mask label shape mismatch (4000, 1824) (3264, 2448)\n",
            "=> saving checkpoint to output1.6.0/taco/seg_hrnet_w18_small_cls5_720x720_sgd_lr4e-3_wd1e-4_bs_16_epoch10_democheckpoint.pth.tar\n",
            "Loss: 0.206, MeanIU:  0.1908, Best_mIoU:  0.1909\n",
            "[9.53296555e-01 0.00000000e+00 5.40749620e-04 0.00000000e+00\n",
            " 2.24488513e-04]\n",
            "Epoch: [6/10] Iter:[0/75], Time: 6.12, lr: 0.001754, Loss: 0.091596\n",
            "Epoch: [6/10] Iter:[50/75], Time: 1.99, lr: 0.001488, Loss: 0.327039\n",
            "Epoch: [6/10] Iter:[100/75], Time: 2.06, lr: 0.001217, Loss: 0.319549\n",
            "Epoch: [6/10] Iter:[150/75], Time: 2.04, lr: 0.000940, Loss: 0.310674\n",
            "Epoch: [6/10] Iter:[200/75], Time: 2.01, lr: 0.000652, Loss: 0.302489\n",
            "Epoch: [6/10] Iter:[250/75], Time: 1.99, lr: 0.000350, Loss: 0.291663\n",
            "mask label shape mismatch (4000, 1824) (3264, 2448)\n",
            "=> saving checkpoint to output1.6.0/taco/seg_hrnet_w18_small_cls5_720x720_sgd_lr4e-3_wd1e-4_bs_16_epoch10_democheckpoint.pth.tar\n",
            "Loss: 0.206, MeanIU:  0.1910, Best_mIoU:  0.1910\n",
            "[9.53263230e-01 0.00000000e+00 1.49063312e-04 0.00000000e+00\n",
            " 1.53958304e-03]\n",
            "Epoch: [7/10] Iter:[0/75], Time: 11.79, lr: 0.001354, Loss: 1.508374\n",
            "Epoch: [7/10] Iter:[50/75], Time: 2.07, lr: 0.001080, Loss: 0.362881\n",
            "Epoch: [7/10] Iter:[100/75], Time: 2.00, lr: 0.000797, Loss: 0.340238\n",
            "Epoch: [7/10] Iter:[150/75], Time: 1.98, lr: 0.000504, Loss: 0.319321\n",
            "mask label shape mismatch (4000, 1824) (3264, 2448)\n",
            "Epoch: [7/10] Iter:[200/75], Time: 1.92, lr: 0.000187, Loss: 0.307789\n",
            "Epoch: [7/10] Iter:[250/75], Time: 1.93, lr: 0.000001, Loss: 0.313909\n",
            "=> saving checkpoint to output1.6.0/taco/seg_hrnet_w18_small_cls5_720x720_sgd_lr4e-3_wd1e-4_bs_16_epoch10_democheckpoint.pth.tar\n",
            "Loss: 0.208, MeanIU:  0.1963, Best_mIoU:  0.1963\n",
            "[0.95295773 0.         0.00234518 0.         0.02602009]\n",
            "Epoch: [8/10] Iter:[0/75], Time: 8.77, lr: 0.000940, Loss: 0.369370\n",
            "Epoch: [8/10] Iter:[50/75], Time: 2.05, lr: 0.000652, Loss: 0.302028\n",
            "Epoch: [8/10] Iter:[100/75], Time: 1.96, lr: 0.000350, Loss: 0.301443\n",
            "mask label shape mismatch (4000, 1824) (3264, 2448)\n",
            "Epoch: [8/10] Iter:[150/75], Time: 1.99, lr: 0.000001, Loss: 0.305588\n",
            "Epoch: [8/10] Iter:[200/75], Time: 1.99, lr: 0.000001, Loss: 0.291888\n",
            "Epoch: [8/10] Iter:[250/75], Time: 1.99, lr: 0.000001, Loss: 0.298071\n",
            "=> saving checkpoint to output1.6.0/taco/seg_hrnet_w18_small_cls5_720x720_sgd_lr4e-3_wd1e-4_bs_16_epoch10_democheckpoint.pth.tar\n",
            "Loss: 0.213, MeanIU:  0.1909, Best_mIoU:  0.1963\n",
            "[0.95303506 0.         0.00148983 0.         0.        ]\n",
            "Epoch: [9/10] Iter:[0/75], Time: 5.71, lr: 0.000504, Loss: 0.786698\n",
            "Epoch: [9/10] Iter:[50/75], Time: 2.21, lr: 0.000187, Loss: 0.306472\n",
            "mask label shape mismatch (4000, 1824) (3264, 2448)\n",
            "Epoch: [9/10] Iter:[100/75], Time: 2.00, lr: 0.000001, Loss: 0.322770\n",
            "Epoch: [9/10] Iter:[150/75], Time: 1.97, lr: 0.000001, Loss: 0.322560\n",
            "Epoch: [9/10] Iter:[200/75], Time: 1.96, lr: 0.000001, Loss: 0.319477\n",
            "Epoch: [9/10] Iter:[250/75], Time: 1.94, lr: 0.000001, Loss: 0.306470\n",
            "=> saving checkpoint to output1.6.0/taco/seg_hrnet_w18_small_cls5_720x720_sgd_lr4e-3_wd1e-4_bs_16_epoch10_democheckpoint.pth.tar\n",
            "Loss: 0.212, MeanIU:  0.1908, Best_mIoU:  0.1963\n",
            "[0.95315273 0.         0.00097114 0.         0.        ]\n",
            "Hours: 1\n",
            "Done\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TWi2_PeyeUr"
      },
      "source": [
        "### **5. Executing HRNet Test with TACO**\n",
        "\n",
        "*Observation:* the validation has a poor performance because the number of epochs for training are not enough. But again, this is a demo only."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxFJ7F933OOL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcb5e6d9-fdcc-4c8f-cb08-896cfc463643"
      },
      "source": [
        "%cd /content/HRNet\n",
        "!python3 tools/test.py --cfg experiments/taco/seg_hrnet_w18_small_cls5_720x720_sgd_lr4e-3_wd1e-4_bs_16_epoch10_demo.yaml TEST.MODEL_FILE output1.6.0/taco/seg_hrnet_w18_small_cls5_720x720_sgd_lr4e-3_wd1e-4_bs_16_epoch10_demo/final_state.pth TEST.BATCH_SIZE_PER_GPU 32\n",
        "%cd ../"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/HRNet\n",
            "=> creating output/taco/seg_hrnet_w18_small_cls5_720x720_sgd_lr4e-3_wd1e-4_bs_16_epoch10_demo\n",
            "=> creating log/taco/seg_hrnet/seg_hrnet_w18_small_cls5_720x720_sgd_lr4e-3_wd1e-4_bs_16_epoch10_demo_2021-01-20-21-34\n",
            "Namespace(cfg='experiments/taco/seg_hrnet_w18_small_cls5_720x720_sgd_lr4e-3_wd1e-4_bs_16_epoch10_demo.yaml', opts=['TEST.MODEL_FILE', 'output1.6.0/taco/seg_hrnet_w18_small_cls5_720x720_sgd_lr4e-3_wd1e-4_bs_16_epoch10_demo/final_state.pth', 'TEST.BATCH_SIZE_PER_GPU', '32'])\n",
            "{'AUTO_RESUME': False,\n",
            " 'CUDNN': CfgNode({'BENCHMARK': True, 'DETERMINISTIC': False, 'ENABLED': True}),\n",
            " 'DATASET': {'DATASET': 'taco',\n",
            "             'EXTRA_TRAIN_SET': '',\n",
            "             'NUM_CLASSES': 5,\n",
            "             'ROOT': '/TACO/data/',\n",
            "             'TEST_SET': 'val',\n",
            "             'TRAIN_SET': 'train'},\n",
            " 'DEBUG': {'DEBUG': False,\n",
            "           'SAVE_BATCH_IMAGES_GT': False,\n",
            "           'SAVE_BATCH_IMAGES_PRED': False,\n",
            "           'SAVE_HEATMAPS_GT': False,\n",
            "           'SAVE_HEATMAPS_PRED': False},\n",
            " 'GPUS': (0, 1, 2, 3),\n",
            " 'LOG_DIR': 'log',\n",
            " 'LOSS': {'CLASS_BALANCE': True,\n",
            "          'OHEMKEEP': 131072,\n",
            "          'OHEMTHRES': 0.9,\n",
            "          'USE_OHEM': False},\n",
            " 'MODEL': {'EXTRA': {'FINAL_CONV_KERNEL': 1,\n",
            "                     'STAGE1': {'BLOCK': 'BOTTLENECK',\n",
            "                                'FUSE_METHOD': 'SUM',\n",
            "                                'NUM_BLOCKS': [2],\n",
            "                                'NUM_CHANNELS': [64],\n",
            "                                'NUM_MODULES': 1,\n",
            "                                'NUM_RANCHES': 1},\n",
            "                     'STAGE2': {'BLOCK': 'BASIC',\n",
            "                                'FUSE_METHOD': 'SUM',\n",
            "                                'NUM_BLOCKS': [2, 2],\n",
            "                                'NUM_BRANCHES': 2,\n",
            "                                'NUM_CHANNELS': [18, 36],\n",
            "                                'NUM_MODULES': 1},\n",
            "                     'STAGE3': {'BLOCK': 'BASIC',\n",
            "                                'FUSE_METHOD': 'SUM',\n",
            "                                'NUM_BLOCKS': [2, 2, 2],\n",
            "                                'NUM_BRANCHES': 3,\n",
            "                                'NUM_CHANNELS': [18, 36, 72],\n",
            "                                'NUM_MODULES': 3},\n",
            "                     'STAGE4': {'BLOCK': 'BASIC',\n",
            "                                'FUSE_METHOD': 'SUM',\n",
            "                                'NUM_BLOCKS': [2, 2, 2, 2],\n",
            "                                'NUM_BRANCHES': 4,\n",
            "                                'NUM_CHANNELS': [18, 36, 72, 144],\n",
            "                                'NUM_MODULES': 2}},\n",
            "           'NAME': 'seg_hrnet',\n",
            "           'PRETRAINED': 'pretrained_models/hrnet_w18_small_model_v2.pth'},\n",
            " 'OUTPUT_DIR': 'output',\n",
            " 'PIN_MEMORY': True,\n",
            " 'PRINT_FREQ': 50,\n",
            " 'RANK': 0,\n",
            " 'TEST': {'BASE_SIZE': 1080,\n",
            "          'BATCH_SIZE_PER_GPU': 32,\n",
            "          'CENTER_CROP_TEST': False,\n",
            "          'FLIP_TEST': False,\n",
            "          'IMAGE_SIZE': [720, 720],\n",
            "          'MODEL_FILE': 'output1.6.0/taco/seg_hrnet_w18_small_cls5_720x720_sgd_lr4e-3_wd1e-4_bs_16_epoch10_demo/final_state.pth',\n",
            "          'MULTI_SCALE': False,\n",
            "          'NUM_SAMPLES': 0,\n",
            "          'SCALE_LIST': [1]},\n",
            " 'TRAIN': {'BASE_SIZE': 1080,\n",
            "           'BATCH_SIZE_PER_GPU': 4,\n",
            "           'BEGIN_EPOCH': 0,\n",
            "           'DOWNSAMPLERATE': 1,\n",
            "           'END_EPOCH': 10,\n",
            "           'EXTRA_EPOCH': 0,\n",
            "           'EXTRA_LR': 0.001,\n",
            "           'FLIP': True,\n",
            "           'IGNORE_LABEL': -1,\n",
            "           'IMAGE_SIZE': [720, 720],\n",
            "           'LR': 0.004,\n",
            "           'LR_FACTOR': 0.1,\n",
            "           'LR_STEP': [90, 110],\n",
            "           'MOMENTUM': 0.9,\n",
            "           'MULTI_SCALE': True,\n",
            "           'NESTEROV': False,\n",
            "           'NUM_SAMPLES': 0,\n",
            "           'OPTIMIZER': 'sgd',\n",
            "           'RESUME': False,\n",
            "           'SCALE_FACTOR': 16,\n",
            "           'SHUFFLE': True,\n",
            "           'WD': 0.0001},\n",
            " 'WORKERS': 4}\n",
            "=> init weights from normal distribution\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "\n",
            "Total Parameters: 3,935,785\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "Total Multiply Adds (For Convolution and Linear Layers only): 17.620910458266735 GFLOPs\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "Number of Layers\n",
            "Conv2d : 146 layers   BatchNorm2d : 145 layers   ReLU : 119 layers   Bottleneck : 2 layers   BasicBlock : 38 layers   HighResolutionModule : 6 layers   \n",
            "=> loading model from output1.6.0/taco/seg_hrnet_w18_small_cls5_720x720_sgd_lr4e-3_wd1e-4_bs_16_epoch10_demo/final_state.pth\n",
            "=> loading conv1.weight from pretrained model\n",
            "=> loading bn1.weight from pretrained model\n",
            "=> loading bn1.bias from pretrained model\n",
            "=> loading bn1.running_mean from pretrained model\n",
            "=> loading bn1.running_var from pretrained model\n",
            "=> loading bn1.num_batches_tracked from pretrained model\n",
            "=> loading conv2.weight from pretrained model\n",
            "=> loading bn2.weight from pretrained model\n",
            "=> loading bn2.bias from pretrained model\n",
            "=> loading bn2.running_mean from pretrained model\n",
            "=> loading bn2.running_var from pretrained model\n",
            "=> loading bn2.num_batches_tracked from pretrained model\n",
            "=> loading layer1.0.conv1.weight from pretrained model\n",
            "=> loading layer1.0.bn1.weight from pretrained model\n",
            "=> loading layer1.0.bn1.bias from pretrained model\n",
            "=> loading layer1.0.bn1.running_mean from pretrained model\n",
            "=> loading layer1.0.bn1.running_var from pretrained model\n",
            "=> loading layer1.0.bn1.num_batches_tracked from pretrained model\n",
            "=> loading layer1.0.conv2.weight from pretrained model\n",
            "=> loading layer1.0.bn2.weight from pretrained model\n",
            "=> loading layer1.0.bn2.bias from pretrained model\n",
            "=> loading layer1.0.bn2.running_mean from pretrained model\n",
            "=> loading layer1.0.bn2.running_var from pretrained model\n",
            "=> loading layer1.0.bn2.num_batches_tracked from pretrained model\n",
            "=> loading layer1.0.conv3.weight from pretrained model\n",
            "=> loading layer1.0.bn3.weight from pretrained model\n",
            "=> loading layer1.0.bn3.bias from pretrained model\n",
            "=> loading layer1.0.bn3.running_mean from pretrained model\n",
            "=> loading layer1.0.bn3.running_var from pretrained model\n",
            "=> loading layer1.0.bn3.num_batches_tracked from pretrained model\n",
            "=> loading layer1.0.downsample.0.weight from pretrained model\n",
            "=> loading layer1.0.downsample.1.weight from pretrained model\n",
            "=> loading layer1.0.downsample.1.bias from pretrained model\n",
            "=> loading layer1.0.downsample.1.running_mean from pretrained model\n",
            "=> loading layer1.0.downsample.1.running_var from pretrained model\n",
            "=> loading layer1.0.downsample.1.num_batches_tracked from pretrained model\n",
            "=> loading layer1.1.conv1.weight from pretrained model\n",
            "=> loading layer1.1.bn1.weight from pretrained model\n",
            "=> loading layer1.1.bn1.bias from pretrained model\n",
            "=> loading layer1.1.bn1.running_mean from pretrained model\n",
            "=> loading layer1.1.bn1.running_var from pretrained model\n",
            "=> loading layer1.1.bn1.num_batches_tracked from pretrained model\n",
            "=> loading layer1.1.conv2.weight from pretrained model\n",
            "=> loading layer1.1.bn2.weight from pretrained model\n",
            "=> loading layer1.1.bn2.bias from pretrained model\n",
            "=> loading layer1.1.bn2.running_mean from pretrained model\n",
            "=> loading layer1.1.bn2.running_var from pretrained model\n",
            "=> loading layer1.1.bn2.num_batches_tracked from pretrained model\n",
            "=> loading layer1.1.conv3.weight from pretrained model\n",
            "=> loading layer1.1.bn3.weight from pretrained model\n",
            "=> loading layer1.1.bn3.bias from pretrained model\n",
            "=> loading layer1.1.bn3.running_mean from pretrained model\n",
            "=> loading layer1.1.bn3.running_var from pretrained model\n",
            "=> loading layer1.1.bn3.num_batches_tracked from pretrained model\n",
            "=> loading transition1.0.0.weight from pretrained model\n",
            "=> loading transition1.0.1.weight from pretrained model\n",
            "=> loading transition1.0.1.bias from pretrained model\n",
            "=> loading transition1.0.1.running_mean from pretrained model\n",
            "=> loading transition1.0.1.running_var from pretrained model\n",
            "=> loading transition1.0.1.num_batches_tracked from pretrained model\n",
            "=> loading transition1.1.0.0.weight from pretrained model\n",
            "=> loading transition1.1.0.1.weight from pretrained model\n",
            "=> loading transition1.1.0.1.bias from pretrained model\n",
            "=> loading transition1.1.0.1.running_mean from pretrained model\n",
            "=> loading transition1.1.0.1.running_var from pretrained model\n",
            "=> loading transition1.1.0.1.num_batches_tracked from pretrained model\n",
            "=> loading stage2.0.branches.0.0.conv1.weight from pretrained model\n",
            "=> loading stage2.0.branches.0.0.bn1.weight from pretrained model\n",
            "=> loading stage2.0.branches.0.0.bn1.bias from pretrained model\n",
            "=> loading stage2.0.branches.0.0.bn1.running_mean from pretrained model\n",
            "=> loading stage2.0.branches.0.0.bn1.running_var from pretrained model\n",
            "=> loading stage2.0.branches.0.0.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage2.0.branches.0.0.conv2.weight from pretrained model\n",
            "=> loading stage2.0.branches.0.0.bn2.weight from pretrained model\n",
            "=> loading stage2.0.branches.0.0.bn2.bias from pretrained model\n",
            "=> loading stage2.0.branches.0.0.bn2.running_mean from pretrained model\n",
            "=> loading stage2.0.branches.0.0.bn2.running_var from pretrained model\n",
            "=> loading stage2.0.branches.0.0.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage2.0.branches.0.1.conv1.weight from pretrained model\n",
            "=> loading stage2.0.branches.0.1.bn1.weight from pretrained model\n",
            "=> loading stage2.0.branches.0.1.bn1.bias from pretrained model\n",
            "=> loading stage2.0.branches.0.1.bn1.running_mean from pretrained model\n",
            "=> loading stage2.0.branches.0.1.bn1.running_var from pretrained model\n",
            "=> loading stage2.0.branches.0.1.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage2.0.branches.0.1.conv2.weight from pretrained model\n",
            "=> loading stage2.0.branches.0.1.bn2.weight from pretrained model\n",
            "=> loading stage2.0.branches.0.1.bn2.bias from pretrained model\n",
            "=> loading stage2.0.branches.0.1.bn2.running_mean from pretrained model\n",
            "=> loading stage2.0.branches.0.1.bn2.running_var from pretrained model\n",
            "=> loading stage2.0.branches.0.1.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage2.0.branches.1.0.conv1.weight from pretrained model\n",
            "=> loading stage2.0.branches.1.0.bn1.weight from pretrained model\n",
            "=> loading stage2.0.branches.1.0.bn1.bias from pretrained model\n",
            "=> loading stage2.0.branches.1.0.bn1.running_mean from pretrained model\n",
            "=> loading stage2.0.branches.1.0.bn1.running_var from pretrained model\n",
            "=> loading stage2.0.branches.1.0.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage2.0.branches.1.0.conv2.weight from pretrained model\n",
            "=> loading stage2.0.branches.1.0.bn2.weight from pretrained model\n",
            "=> loading stage2.0.branches.1.0.bn2.bias from pretrained model\n",
            "=> loading stage2.0.branches.1.0.bn2.running_mean from pretrained model\n",
            "=> loading stage2.0.branches.1.0.bn2.running_var from pretrained model\n",
            "=> loading stage2.0.branches.1.0.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage2.0.branches.1.1.conv1.weight from pretrained model\n",
            "=> loading stage2.0.branches.1.1.bn1.weight from pretrained model\n",
            "=> loading stage2.0.branches.1.1.bn1.bias from pretrained model\n",
            "=> loading stage2.0.branches.1.1.bn1.running_mean from pretrained model\n",
            "=> loading stage2.0.branches.1.1.bn1.running_var from pretrained model\n",
            "=> loading stage2.0.branches.1.1.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage2.0.branches.1.1.conv2.weight from pretrained model\n",
            "=> loading stage2.0.branches.1.1.bn2.weight from pretrained model\n",
            "=> loading stage2.0.branches.1.1.bn2.bias from pretrained model\n",
            "=> loading stage2.0.branches.1.1.bn2.running_mean from pretrained model\n",
            "=> loading stage2.0.branches.1.1.bn2.running_var from pretrained model\n",
            "=> loading stage2.0.branches.1.1.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage2.0.fuse_layers.0.1.0.weight from pretrained model\n",
            "=> loading stage2.0.fuse_layers.0.1.1.weight from pretrained model\n",
            "=> loading stage2.0.fuse_layers.0.1.1.bias from pretrained model\n",
            "=> loading stage2.0.fuse_layers.0.1.1.running_mean from pretrained model\n",
            "=> loading stage2.0.fuse_layers.0.1.1.running_var from pretrained model\n",
            "=> loading stage2.0.fuse_layers.0.1.1.num_batches_tracked from pretrained model\n",
            "=> loading stage2.0.fuse_layers.1.0.0.0.weight from pretrained model\n",
            "=> loading stage2.0.fuse_layers.1.0.0.1.weight from pretrained model\n",
            "=> loading stage2.0.fuse_layers.1.0.0.1.bias from pretrained model\n",
            "=> loading stage2.0.fuse_layers.1.0.0.1.running_mean from pretrained model\n",
            "=> loading stage2.0.fuse_layers.1.0.0.1.running_var from pretrained model\n",
            "=> loading stage2.0.fuse_layers.1.0.0.1.num_batches_tracked from pretrained model\n",
            "=> loading transition2.2.0.0.weight from pretrained model\n",
            "=> loading transition2.2.0.1.weight from pretrained model\n",
            "=> loading transition2.2.0.1.bias from pretrained model\n",
            "=> loading transition2.2.0.1.running_mean from pretrained model\n",
            "=> loading transition2.2.0.1.running_var from pretrained model\n",
            "=> loading transition2.2.0.1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.0.branches.0.0.conv1.weight from pretrained model\n",
            "=> loading stage3.0.branches.0.0.bn1.weight from pretrained model\n",
            "=> loading stage3.0.branches.0.0.bn1.bias from pretrained model\n",
            "=> loading stage3.0.branches.0.0.bn1.running_mean from pretrained model\n",
            "=> loading stage3.0.branches.0.0.bn1.running_var from pretrained model\n",
            "=> loading stage3.0.branches.0.0.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.0.branches.0.0.conv2.weight from pretrained model\n",
            "=> loading stage3.0.branches.0.0.bn2.weight from pretrained model\n",
            "=> loading stage3.0.branches.0.0.bn2.bias from pretrained model\n",
            "=> loading stage3.0.branches.0.0.bn2.running_mean from pretrained model\n",
            "=> loading stage3.0.branches.0.0.bn2.running_var from pretrained model\n",
            "=> loading stage3.0.branches.0.0.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage3.0.branches.0.1.conv1.weight from pretrained model\n",
            "=> loading stage3.0.branches.0.1.bn1.weight from pretrained model\n",
            "=> loading stage3.0.branches.0.1.bn1.bias from pretrained model\n",
            "=> loading stage3.0.branches.0.1.bn1.running_mean from pretrained model\n",
            "=> loading stage3.0.branches.0.1.bn1.running_var from pretrained model\n",
            "=> loading stage3.0.branches.0.1.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.0.branches.0.1.conv2.weight from pretrained model\n",
            "=> loading stage3.0.branches.0.1.bn2.weight from pretrained model\n",
            "=> loading stage3.0.branches.0.1.bn2.bias from pretrained model\n",
            "=> loading stage3.0.branches.0.1.bn2.running_mean from pretrained model\n",
            "=> loading stage3.0.branches.0.1.bn2.running_var from pretrained model\n",
            "=> loading stage3.0.branches.0.1.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage3.0.branches.1.0.conv1.weight from pretrained model\n",
            "=> loading stage3.0.branches.1.0.bn1.weight from pretrained model\n",
            "=> loading stage3.0.branches.1.0.bn1.bias from pretrained model\n",
            "=> loading stage3.0.branches.1.0.bn1.running_mean from pretrained model\n",
            "=> loading stage3.0.branches.1.0.bn1.running_var from pretrained model\n",
            "=> loading stage3.0.branches.1.0.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.0.branches.1.0.conv2.weight from pretrained model\n",
            "=> loading stage3.0.branches.1.0.bn2.weight from pretrained model\n",
            "=> loading stage3.0.branches.1.0.bn2.bias from pretrained model\n",
            "=> loading stage3.0.branches.1.0.bn2.running_mean from pretrained model\n",
            "=> loading stage3.0.branches.1.0.bn2.running_var from pretrained model\n",
            "=> loading stage3.0.branches.1.0.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage3.0.branches.1.1.conv1.weight from pretrained model\n",
            "=> loading stage3.0.branches.1.1.bn1.weight from pretrained model\n",
            "=> loading stage3.0.branches.1.1.bn1.bias from pretrained model\n",
            "=> loading stage3.0.branches.1.1.bn1.running_mean from pretrained model\n",
            "=> loading stage3.0.branches.1.1.bn1.running_var from pretrained model\n",
            "=> loading stage3.0.branches.1.1.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.0.branches.1.1.conv2.weight from pretrained model\n",
            "=> loading stage3.0.branches.1.1.bn2.weight from pretrained model\n",
            "=> loading stage3.0.branches.1.1.bn2.bias from pretrained model\n",
            "=> loading stage3.0.branches.1.1.bn2.running_mean from pretrained model\n",
            "=> loading stage3.0.branches.1.1.bn2.running_var from pretrained model\n",
            "=> loading stage3.0.branches.1.1.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage3.0.branches.2.0.conv1.weight from pretrained model\n",
            "=> loading stage3.0.branches.2.0.bn1.weight from pretrained model\n",
            "=> loading stage3.0.branches.2.0.bn1.bias from pretrained model\n",
            "=> loading stage3.0.branches.2.0.bn1.running_mean from pretrained model\n",
            "=> loading stage3.0.branches.2.0.bn1.running_var from pretrained model\n",
            "=> loading stage3.0.branches.2.0.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.0.branches.2.0.conv2.weight from pretrained model\n",
            "=> loading stage3.0.branches.2.0.bn2.weight from pretrained model\n",
            "=> loading stage3.0.branches.2.0.bn2.bias from pretrained model\n",
            "=> loading stage3.0.branches.2.0.bn2.running_mean from pretrained model\n",
            "=> loading stage3.0.branches.2.0.bn2.running_var from pretrained model\n",
            "=> loading stage3.0.branches.2.0.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage3.0.branches.2.1.conv1.weight from pretrained model\n",
            "=> loading stage3.0.branches.2.1.bn1.weight from pretrained model\n",
            "=> loading stage3.0.branches.2.1.bn1.bias from pretrained model\n",
            "=> loading stage3.0.branches.2.1.bn1.running_mean from pretrained model\n",
            "=> loading stage3.0.branches.2.1.bn1.running_var from pretrained model\n",
            "=> loading stage3.0.branches.2.1.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.0.branches.2.1.conv2.weight from pretrained model\n",
            "=> loading stage3.0.branches.2.1.bn2.weight from pretrained model\n",
            "=> loading stage3.0.branches.2.1.bn2.bias from pretrained model\n",
            "=> loading stage3.0.branches.2.1.bn2.running_mean from pretrained model\n",
            "=> loading stage3.0.branches.2.1.bn2.running_var from pretrained model\n",
            "=> loading stage3.0.branches.2.1.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage3.0.fuse_layers.0.1.0.weight from pretrained model\n",
            "=> loading stage3.0.fuse_layers.0.1.1.weight from pretrained model\n",
            "=> loading stage3.0.fuse_layers.0.1.1.bias from pretrained model\n",
            "=> loading stage3.0.fuse_layers.0.1.1.running_mean from pretrained model\n",
            "=> loading stage3.0.fuse_layers.0.1.1.running_var from pretrained model\n",
            "=> loading stage3.0.fuse_layers.0.1.1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.0.fuse_layers.0.2.0.weight from pretrained model\n",
            "=> loading stage3.0.fuse_layers.0.2.1.weight from pretrained model\n",
            "=> loading stage3.0.fuse_layers.0.2.1.bias from pretrained model\n",
            "=> loading stage3.0.fuse_layers.0.2.1.running_mean from pretrained model\n",
            "=> loading stage3.0.fuse_layers.0.2.1.running_var from pretrained model\n",
            "=> loading stage3.0.fuse_layers.0.2.1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.0.fuse_layers.1.0.0.0.weight from pretrained model\n",
            "=> loading stage3.0.fuse_layers.1.0.0.1.weight from pretrained model\n",
            "=> loading stage3.0.fuse_layers.1.0.0.1.bias from pretrained model\n",
            "=> loading stage3.0.fuse_layers.1.0.0.1.running_mean from pretrained model\n",
            "=> loading stage3.0.fuse_layers.1.0.0.1.running_var from pretrained model\n",
            "=> loading stage3.0.fuse_layers.1.0.0.1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.0.fuse_layers.1.2.0.weight from pretrained model\n",
            "=> loading stage3.0.fuse_layers.1.2.1.weight from pretrained model\n",
            "=> loading stage3.0.fuse_layers.1.2.1.bias from pretrained model\n",
            "=> loading stage3.0.fuse_layers.1.2.1.running_mean from pretrained model\n",
            "=> loading stage3.0.fuse_layers.1.2.1.running_var from pretrained model\n",
            "=> loading stage3.0.fuse_layers.1.2.1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.0.fuse_layers.2.0.0.0.weight from pretrained model\n",
            "=> loading stage3.0.fuse_layers.2.0.0.1.weight from pretrained model\n",
            "=> loading stage3.0.fuse_layers.2.0.0.1.bias from pretrained model\n",
            "=> loading stage3.0.fuse_layers.2.0.0.1.running_mean from pretrained model\n",
            "=> loading stage3.0.fuse_layers.2.0.0.1.running_var from pretrained model\n",
            "=> loading stage3.0.fuse_layers.2.0.0.1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.0.fuse_layers.2.0.1.0.weight from pretrained model\n",
            "=> loading stage3.0.fuse_layers.2.0.1.1.weight from pretrained model\n",
            "=> loading stage3.0.fuse_layers.2.0.1.1.bias from pretrained model\n",
            "=> loading stage3.0.fuse_layers.2.0.1.1.running_mean from pretrained model\n",
            "=> loading stage3.0.fuse_layers.2.0.1.1.running_var from pretrained model\n",
            "=> loading stage3.0.fuse_layers.2.0.1.1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.0.fuse_layers.2.1.0.0.weight from pretrained model\n",
            "=> loading stage3.0.fuse_layers.2.1.0.1.weight from pretrained model\n",
            "=> loading stage3.0.fuse_layers.2.1.0.1.bias from pretrained model\n",
            "=> loading stage3.0.fuse_layers.2.1.0.1.running_mean from pretrained model\n",
            "=> loading stage3.0.fuse_layers.2.1.0.1.running_var from pretrained model\n",
            "=> loading stage3.0.fuse_layers.2.1.0.1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.1.branches.0.0.conv1.weight from pretrained model\n",
            "=> loading stage3.1.branches.0.0.bn1.weight from pretrained model\n",
            "=> loading stage3.1.branches.0.0.bn1.bias from pretrained model\n",
            "=> loading stage3.1.branches.0.0.bn1.running_mean from pretrained model\n",
            "=> loading stage3.1.branches.0.0.bn1.running_var from pretrained model\n",
            "=> loading stage3.1.branches.0.0.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.1.branches.0.0.conv2.weight from pretrained model\n",
            "=> loading stage3.1.branches.0.0.bn2.weight from pretrained model\n",
            "=> loading stage3.1.branches.0.0.bn2.bias from pretrained model\n",
            "=> loading stage3.1.branches.0.0.bn2.running_mean from pretrained model\n",
            "=> loading stage3.1.branches.0.0.bn2.running_var from pretrained model\n",
            "=> loading stage3.1.branches.0.0.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage3.1.branches.0.1.conv1.weight from pretrained model\n",
            "=> loading stage3.1.branches.0.1.bn1.weight from pretrained model\n",
            "=> loading stage3.1.branches.0.1.bn1.bias from pretrained model\n",
            "=> loading stage3.1.branches.0.1.bn1.running_mean from pretrained model\n",
            "=> loading stage3.1.branches.0.1.bn1.running_var from pretrained model\n",
            "=> loading stage3.1.branches.0.1.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.1.branches.0.1.conv2.weight from pretrained model\n",
            "=> loading stage3.1.branches.0.1.bn2.weight from pretrained model\n",
            "=> loading stage3.1.branches.0.1.bn2.bias from pretrained model\n",
            "=> loading stage3.1.branches.0.1.bn2.running_mean from pretrained model\n",
            "=> loading stage3.1.branches.0.1.bn2.running_var from pretrained model\n",
            "=> loading stage3.1.branches.0.1.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage3.1.branches.1.0.conv1.weight from pretrained model\n",
            "=> loading stage3.1.branches.1.0.bn1.weight from pretrained model\n",
            "=> loading stage3.1.branches.1.0.bn1.bias from pretrained model\n",
            "=> loading stage3.1.branches.1.0.bn1.running_mean from pretrained model\n",
            "=> loading stage3.1.branches.1.0.bn1.running_var from pretrained model\n",
            "=> loading stage3.1.branches.1.0.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.1.branches.1.0.conv2.weight from pretrained model\n",
            "=> loading stage3.1.branches.1.0.bn2.weight from pretrained model\n",
            "=> loading stage3.1.branches.1.0.bn2.bias from pretrained model\n",
            "=> loading stage3.1.branches.1.0.bn2.running_mean from pretrained model\n",
            "=> loading stage3.1.branches.1.0.bn2.running_var from pretrained model\n",
            "=> loading stage3.1.branches.1.0.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage3.1.branches.1.1.conv1.weight from pretrained model\n",
            "=> loading stage3.1.branches.1.1.bn1.weight from pretrained model\n",
            "=> loading stage3.1.branches.1.1.bn1.bias from pretrained model\n",
            "=> loading stage3.1.branches.1.1.bn1.running_mean from pretrained model\n",
            "=> loading stage3.1.branches.1.1.bn1.running_var from pretrained model\n",
            "=> loading stage3.1.branches.1.1.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.1.branches.1.1.conv2.weight from pretrained model\n",
            "=> loading stage3.1.branches.1.1.bn2.weight from pretrained model\n",
            "=> loading stage3.1.branches.1.1.bn2.bias from pretrained model\n",
            "=> loading stage3.1.branches.1.1.bn2.running_mean from pretrained model\n",
            "=> loading stage3.1.branches.1.1.bn2.running_var from pretrained model\n",
            "=> loading stage3.1.branches.1.1.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage3.1.branches.2.0.conv1.weight from pretrained model\n",
            "=> loading stage3.1.branches.2.0.bn1.weight from pretrained model\n",
            "=> loading stage3.1.branches.2.0.bn1.bias from pretrained model\n",
            "=> loading stage3.1.branches.2.0.bn1.running_mean from pretrained model\n",
            "=> loading stage3.1.branches.2.0.bn1.running_var from pretrained model\n",
            "=> loading stage3.1.branches.2.0.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.1.branches.2.0.conv2.weight from pretrained model\n",
            "=> loading stage3.1.branches.2.0.bn2.weight from pretrained model\n",
            "=> loading stage3.1.branches.2.0.bn2.bias from pretrained model\n",
            "=> loading stage3.1.branches.2.0.bn2.running_mean from pretrained model\n",
            "=> loading stage3.1.branches.2.0.bn2.running_var from pretrained model\n",
            "=> loading stage3.1.branches.2.0.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage3.1.branches.2.1.conv1.weight from pretrained model\n",
            "=> loading stage3.1.branches.2.1.bn1.weight from pretrained model\n",
            "=> loading stage3.1.branches.2.1.bn1.bias from pretrained model\n",
            "=> loading stage3.1.branches.2.1.bn1.running_mean from pretrained model\n",
            "=> loading stage3.1.branches.2.1.bn1.running_var from pretrained model\n",
            "=> loading stage3.1.branches.2.1.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.1.branches.2.1.conv2.weight from pretrained model\n",
            "=> loading stage3.1.branches.2.1.bn2.weight from pretrained model\n",
            "=> loading stage3.1.branches.2.1.bn2.bias from pretrained model\n",
            "=> loading stage3.1.branches.2.1.bn2.running_mean from pretrained model\n",
            "=> loading stage3.1.branches.2.1.bn2.running_var from pretrained model\n",
            "=> loading stage3.1.branches.2.1.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage3.1.fuse_layers.0.1.0.weight from pretrained model\n",
            "=> loading stage3.1.fuse_layers.0.1.1.weight from pretrained model\n",
            "=> loading stage3.1.fuse_layers.0.1.1.bias from pretrained model\n",
            "=> loading stage3.1.fuse_layers.0.1.1.running_mean from pretrained model\n",
            "=> loading stage3.1.fuse_layers.0.1.1.running_var from pretrained model\n",
            "=> loading stage3.1.fuse_layers.0.1.1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.1.fuse_layers.0.2.0.weight from pretrained model\n",
            "=> loading stage3.1.fuse_layers.0.2.1.weight from pretrained model\n",
            "=> loading stage3.1.fuse_layers.0.2.1.bias from pretrained model\n",
            "=> loading stage3.1.fuse_layers.0.2.1.running_mean from pretrained model\n",
            "=> loading stage3.1.fuse_layers.0.2.1.running_var from pretrained model\n",
            "=> loading stage3.1.fuse_layers.0.2.1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.1.fuse_layers.1.0.0.0.weight from pretrained model\n",
            "=> loading stage3.1.fuse_layers.1.0.0.1.weight from pretrained model\n",
            "=> loading stage3.1.fuse_layers.1.0.0.1.bias from pretrained model\n",
            "=> loading stage3.1.fuse_layers.1.0.0.1.running_mean from pretrained model\n",
            "=> loading stage3.1.fuse_layers.1.0.0.1.running_var from pretrained model\n",
            "=> loading stage3.1.fuse_layers.1.0.0.1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.1.fuse_layers.1.2.0.weight from pretrained model\n",
            "=> loading stage3.1.fuse_layers.1.2.1.weight from pretrained model\n",
            "=> loading stage3.1.fuse_layers.1.2.1.bias from pretrained model\n",
            "=> loading stage3.1.fuse_layers.1.2.1.running_mean from pretrained model\n",
            "=> loading stage3.1.fuse_layers.1.2.1.running_var from pretrained model\n",
            "=> loading stage3.1.fuse_layers.1.2.1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.1.fuse_layers.2.0.0.0.weight from pretrained model\n",
            "=> loading stage3.1.fuse_layers.2.0.0.1.weight from pretrained model\n",
            "=> loading stage3.1.fuse_layers.2.0.0.1.bias from pretrained model\n",
            "=> loading stage3.1.fuse_layers.2.0.0.1.running_mean from pretrained model\n",
            "=> loading stage3.1.fuse_layers.2.0.0.1.running_var from pretrained model\n",
            "=> loading stage3.1.fuse_layers.2.0.0.1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.1.fuse_layers.2.0.1.0.weight from pretrained model\n",
            "=> loading stage3.1.fuse_layers.2.0.1.1.weight from pretrained model\n",
            "=> loading stage3.1.fuse_layers.2.0.1.1.bias from pretrained model\n",
            "=> loading stage3.1.fuse_layers.2.0.1.1.running_mean from pretrained model\n",
            "=> loading stage3.1.fuse_layers.2.0.1.1.running_var from pretrained model\n",
            "=> loading stage3.1.fuse_layers.2.0.1.1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.1.fuse_layers.2.1.0.0.weight from pretrained model\n",
            "=> loading stage3.1.fuse_layers.2.1.0.1.weight from pretrained model\n",
            "=> loading stage3.1.fuse_layers.2.1.0.1.bias from pretrained model\n",
            "=> loading stage3.1.fuse_layers.2.1.0.1.running_mean from pretrained model\n",
            "=> loading stage3.1.fuse_layers.2.1.0.1.running_var from pretrained model\n",
            "=> loading stage3.1.fuse_layers.2.1.0.1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.2.branches.0.0.conv1.weight from pretrained model\n",
            "=> loading stage3.2.branches.0.0.bn1.weight from pretrained model\n",
            "=> loading stage3.2.branches.0.0.bn1.bias from pretrained model\n",
            "=> loading stage3.2.branches.0.0.bn1.running_mean from pretrained model\n",
            "=> loading stage3.2.branches.0.0.bn1.running_var from pretrained model\n",
            "=> loading stage3.2.branches.0.0.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.2.branches.0.0.conv2.weight from pretrained model\n",
            "=> loading stage3.2.branches.0.0.bn2.weight from pretrained model\n",
            "=> loading stage3.2.branches.0.0.bn2.bias from pretrained model\n",
            "=> loading stage3.2.branches.0.0.bn2.running_mean from pretrained model\n",
            "=> loading stage3.2.branches.0.0.bn2.running_var from pretrained model\n",
            "=> loading stage3.2.branches.0.0.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage3.2.branches.0.1.conv1.weight from pretrained model\n",
            "=> loading stage3.2.branches.0.1.bn1.weight from pretrained model\n",
            "=> loading stage3.2.branches.0.1.bn1.bias from pretrained model\n",
            "=> loading stage3.2.branches.0.1.bn1.running_mean from pretrained model\n",
            "=> loading stage3.2.branches.0.1.bn1.running_var from pretrained model\n",
            "=> loading stage3.2.branches.0.1.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.2.branches.0.1.conv2.weight from pretrained model\n",
            "=> loading stage3.2.branches.0.1.bn2.weight from pretrained model\n",
            "=> loading stage3.2.branches.0.1.bn2.bias from pretrained model\n",
            "=> loading stage3.2.branches.0.1.bn2.running_mean from pretrained model\n",
            "=> loading stage3.2.branches.0.1.bn2.running_var from pretrained model\n",
            "=> loading stage3.2.branches.0.1.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage3.2.branches.1.0.conv1.weight from pretrained model\n",
            "=> loading stage3.2.branches.1.0.bn1.weight from pretrained model\n",
            "=> loading stage3.2.branches.1.0.bn1.bias from pretrained model\n",
            "=> loading stage3.2.branches.1.0.bn1.running_mean from pretrained model\n",
            "=> loading stage3.2.branches.1.0.bn1.running_var from pretrained model\n",
            "=> loading stage3.2.branches.1.0.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.2.branches.1.0.conv2.weight from pretrained model\n",
            "=> loading stage3.2.branches.1.0.bn2.weight from pretrained model\n",
            "=> loading stage3.2.branches.1.0.bn2.bias from pretrained model\n",
            "=> loading stage3.2.branches.1.0.bn2.running_mean from pretrained model\n",
            "=> loading stage3.2.branches.1.0.bn2.running_var from pretrained model\n",
            "=> loading stage3.2.branches.1.0.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage3.2.branches.1.1.conv1.weight from pretrained model\n",
            "=> loading stage3.2.branches.1.1.bn1.weight from pretrained model\n",
            "=> loading stage3.2.branches.1.1.bn1.bias from pretrained model\n",
            "=> loading stage3.2.branches.1.1.bn1.running_mean from pretrained model\n",
            "=> loading stage3.2.branches.1.1.bn1.running_var from pretrained model\n",
            "=> loading stage3.2.branches.1.1.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.2.branches.1.1.conv2.weight from pretrained model\n",
            "=> loading stage3.2.branches.1.1.bn2.weight from pretrained model\n",
            "=> loading stage3.2.branches.1.1.bn2.bias from pretrained model\n",
            "=> loading stage3.2.branches.1.1.bn2.running_mean from pretrained model\n",
            "=> loading stage3.2.branches.1.1.bn2.running_var from pretrained model\n",
            "=> loading stage3.2.branches.1.1.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage3.2.branches.2.0.conv1.weight from pretrained model\n",
            "=> loading stage3.2.branches.2.0.bn1.weight from pretrained model\n",
            "=> loading stage3.2.branches.2.0.bn1.bias from pretrained model\n",
            "=> loading stage3.2.branches.2.0.bn1.running_mean from pretrained model\n",
            "=> loading stage3.2.branches.2.0.bn1.running_var from pretrained model\n",
            "=> loading stage3.2.branches.2.0.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.2.branches.2.0.conv2.weight from pretrained model\n",
            "=> loading stage3.2.branches.2.0.bn2.weight from pretrained model\n",
            "=> loading stage3.2.branches.2.0.bn2.bias from pretrained model\n",
            "=> loading stage3.2.branches.2.0.bn2.running_mean from pretrained model\n",
            "=> loading stage3.2.branches.2.0.bn2.running_var from pretrained model\n",
            "=> loading stage3.2.branches.2.0.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage3.2.branches.2.1.conv1.weight from pretrained model\n",
            "=> loading stage3.2.branches.2.1.bn1.weight from pretrained model\n",
            "=> loading stage3.2.branches.2.1.bn1.bias from pretrained model\n",
            "=> loading stage3.2.branches.2.1.bn1.running_mean from pretrained model\n",
            "=> loading stage3.2.branches.2.1.bn1.running_var from pretrained model\n",
            "=> loading stage3.2.branches.2.1.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.2.branches.2.1.conv2.weight from pretrained model\n",
            "=> loading stage3.2.branches.2.1.bn2.weight from pretrained model\n",
            "=> loading stage3.2.branches.2.1.bn2.bias from pretrained model\n",
            "=> loading stage3.2.branches.2.1.bn2.running_mean from pretrained model\n",
            "=> loading stage3.2.branches.2.1.bn2.running_var from pretrained model\n",
            "=> loading stage3.2.branches.2.1.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage3.2.fuse_layers.0.1.0.weight from pretrained model\n",
            "=> loading stage3.2.fuse_layers.0.1.1.weight from pretrained model\n",
            "=> loading stage3.2.fuse_layers.0.1.1.bias from pretrained model\n",
            "=> loading stage3.2.fuse_layers.0.1.1.running_mean from pretrained model\n",
            "=> loading stage3.2.fuse_layers.0.1.1.running_var from pretrained model\n",
            "=> loading stage3.2.fuse_layers.0.1.1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.2.fuse_layers.0.2.0.weight from pretrained model\n",
            "=> loading stage3.2.fuse_layers.0.2.1.weight from pretrained model\n",
            "=> loading stage3.2.fuse_layers.0.2.1.bias from pretrained model\n",
            "=> loading stage3.2.fuse_layers.0.2.1.running_mean from pretrained model\n",
            "=> loading stage3.2.fuse_layers.0.2.1.running_var from pretrained model\n",
            "=> loading stage3.2.fuse_layers.0.2.1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.2.fuse_layers.1.0.0.0.weight from pretrained model\n",
            "=> loading stage3.2.fuse_layers.1.0.0.1.weight from pretrained model\n",
            "=> loading stage3.2.fuse_layers.1.0.0.1.bias from pretrained model\n",
            "=> loading stage3.2.fuse_layers.1.0.0.1.running_mean from pretrained model\n",
            "=> loading stage3.2.fuse_layers.1.0.0.1.running_var from pretrained model\n",
            "=> loading stage3.2.fuse_layers.1.0.0.1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.2.fuse_layers.1.2.0.weight from pretrained model\n",
            "=> loading stage3.2.fuse_layers.1.2.1.weight from pretrained model\n",
            "=> loading stage3.2.fuse_layers.1.2.1.bias from pretrained model\n",
            "=> loading stage3.2.fuse_layers.1.2.1.running_mean from pretrained model\n",
            "=> loading stage3.2.fuse_layers.1.2.1.running_var from pretrained model\n",
            "=> loading stage3.2.fuse_layers.1.2.1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.2.fuse_layers.2.0.0.0.weight from pretrained model\n",
            "=> loading stage3.2.fuse_layers.2.0.0.1.weight from pretrained model\n",
            "=> loading stage3.2.fuse_layers.2.0.0.1.bias from pretrained model\n",
            "=> loading stage3.2.fuse_layers.2.0.0.1.running_mean from pretrained model\n",
            "=> loading stage3.2.fuse_layers.2.0.0.1.running_var from pretrained model\n",
            "=> loading stage3.2.fuse_layers.2.0.0.1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.2.fuse_layers.2.0.1.0.weight from pretrained model\n",
            "=> loading stage3.2.fuse_layers.2.0.1.1.weight from pretrained model\n",
            "=> loading stage3.2.fuse_layers.2.0.1.1.bias from pretrained model\n",
            "=> loading stage3.2.fuse_layers.2.0.1.1.running_mean from pretrained model\n",
            "=> loading stage3.2.fuse_layers.2.0.1.1.running_var from pretrained model\n",
            "=> loading stage3.2.fuse_layers.2.0.1.1.num_batches_tracked from pretrained model\n",
            "=> loading stage3.2.fuse_layers.2.1.0.0.weight from pretrained model\n",
            "=> loading stage3.2.fuse_layers.2.1.0.1.weight from pretrained model\n",
            "=> loading stage3.2.fuse_layers.2.1.0.1.bias from pretrained model\n",
            "=> loading stage3.2.fuse_layers.2.1.0.1.running_mean from pretrained model\n",
            "=> loading stage3.2.fuse_layers.2.1.0.1.running_var from pretrained model\n",
            "=> loading stage3.2.fuse_layers.2.1.0.1.num_batches_tracked from pretrained model\n",
            "=> loading transition3.3.0.0.weight from pretrained model\n",
            "=> loading transition3.3.0.1.weight from pretrained model\n",
            "=> loading transition3.3.0.1.bias from pretrained model\n",
            "=> loading transition3.3.0.1.running_mean from pretrained model\n",
            "=> loading transition3.3.0.1.running_var from pretrained model\n",
            "=> loading transition3.3.0.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.branches.0.0.conv1.weight from pretrained model\n",
            "=> loading stage4.0.branches.0.0.bn1.weight from pretrained model\n",
            "=> loading stage4.0.branches.0.0.bn1.bias from pretrained model\n",
            "=> loading stage4.0.branches.0.0.bn1.running_mean from pretrained model\n",
            "=> loading stage4.0.branches.0.0.bn1.running_var from pretrained model\n",
            "=> loading stage4.0.branches.0.0.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.branches.0.0.conv2.weight from pretrained model\n",
            "=> loading stage4.0.branches.0.0.bn2.weight from pretrained model\n",
            "=> loading stage4.0.branches.0.0.bn2.bias from pretrained model\n",
            "=> loading stage4.0.branches.0.0.bn2.running_mean from pretrained model\n",
            "=> loading stage4.0.branches.0.0.bn2.running_var from pretrained model\n",
            "=> loading stage4.0.branches.0.0.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.branches.0.1.conv1.weight from pretrained model\n",
            "=> loading stage4.0.branches.0.1.bn1.weight from pretrained model\n",
            "=> loading stage4.0.branches.0.1.bn1.bias from pretrained model\n",
            "=> loading stage4.0.branches.0.1.bn1.running_mean from pretrained model\n",
            "=> loading stage4.0.branches.0.1.bn1.running_var from pretrained model\n",
            "=> loading stage4.0.branches.0.1.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.branches.0.1.conv2.weight from pretrained model\n",
            "=> loading stage4.0.branches.0.1.bn2.weight from pretrained model\n",
            "=> loading stage4.0.branches.0.1.bn2.bias from pretrained model\n",
            "=> loading stage4.0.branches.0.1.bn2.running_mean from pretrained model\n",
            "=> loading stage4.0.branches.0.1.bn2.running_var from pretrained model\n",
            "=> loading stage4.0.branches.0.1.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.branches.1.0.conv1.weight from pretrained model\n",
            "=> loading stage4.0.branches.1.0.bn1.weight from pretrained model\n",
            "=> loading stage4.0.branches.1.0.bn1.bias from pretrained model\n",
            "=> loading stage4.0.branches.1.0.bn1.running_mean from pretrained model\n",
            "=> loading stage4.0.branches.1.0.bn1.running_var from pretrained model\n",
            "=> loading stage4.0.branches.1.0.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.branches.1.0.conv2.weight from pretrained model\n",
            "=> loading stage4.0.branches.1.0.bn2.weight from pretrained model\n",
            "=> loading stage4.0.branches.1.0.bn2.bias from pretrained model\n",
            "=> loading stage4.0.branches.1.0.bn2.running_mean from pretrained model\n",
            "=> loading stage4.0.branches.1.0.bn2.running_var from pretrained model\n",
            "=> loading stage4.0.branches.1.0.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.branches.1.1.conv1.weight from pretrained model\n",
            "=> loading stage4.0.branches.1.1.bn1.weight from pretrained model\n",
            "=> loading stage4.0.branches.1.1.bn1.bias from pretrained model\n",
            "=> loading stage4.0.branches.1.1.bn1.running_mean from pretrained model\n",
            "=> loading stage4.0.branches.1.1.bn1.running_var from pretrained model\n",
            "=> loading stage4.0.branches.1.1.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.branches.1.1.conv2.weight from pretrained model\n",
            "=> loading stage4.0.branches.1.1.bn2.weight from pretrained model\n",
            "=> loading stage4.0.branches.1.1.bn2.bias from pretrained model\n",
            "=> loading stage4.0.branches.1.1.bn2.running_mean from pretrained model\n",
            "=> loading stage4.0.branches.1.1.bn2.running_var from pretrained model\n",
            "=> loading stage4.0.branches.1.1.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.branches.2.0.conv1.weight from pretrained model\n",
            "=> loading stage4.0.branches.2.0.bn1.weight from pretrained model\n",
            "=> loading stage4.0.branches.2.0.bn1.bias from pretrained model\n",
            "=> loading stage4.0.branches.2.0.bn1.running_mean from pretrained model\n",
            "=> loading stage4.0.branches.2.0.bn1.running_var from pretrained model\n",
            "=> loading stage4.0.branches.2.0.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.branches.2.0.conv2.weight from pretrained model\n",
            "=> loading stage4.0.branches.2.0.bn2.weight from pretrained model\n",
            "=> loading stage4.0.branches.2.0.bn2.bias from pretrained model\n",
            "=> loading stage4.0.branches.2.0.bn2.running_mean from pretrained model\n",
            "=> loading stage4.0.branches.2.0.bn2.running_var from pretrained model\n",
            "=> loading stage4.0.branches.2.0.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.branches.2.1.conv1.weight from pretrained model\n",
            "=> loading stage4.0.branches.2.1.bn1.weight from pretrained model\n",
            "=> loading stage4.0.branches.2.1.bn1.bias from pretrained model\n",
            "=> loading stage4.0.branches.2.1.bn1.running_mean from pretrained model\n",
            "=> loading stage4.0.branches.2.1.bn1.running_var from pretrained model\n",
            "=> loading stage4.0.branches.2.1.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.branches.2.1.conv2.weight from pretrained model\n",
            "=> loading stage4.0.branches.2.1.bn2.weight from pretrained model\n",
            "=> loading stage4.0.branches.2.1.bn2.bias from pretrained model\n",
            "=> loading stage4.0.branches.2.1.bn2.running_mean from pretrained model\n",
            "=> loading stage4.0.branches.2.1.bn2.running_var from pretrained model\n",
            "=> loading stage4.0.branches.2.1.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.branches.3.0.conv1.weight from pretrained model\n",
            "=> loading stage4.0.branches.3.0.bn1.weight from pretrained model\n",
            "=> loading stage4.0.branches.3.0.bn1.bias from pretrained model\n",
            "=> loading stage4.0.branches.3.0.bn1.running_mean from pretrained model\n",
            "=> loading stage4.0.branches.3.0.bn1.running_var from pretrained model\n",
            "=> loading stage4.0.branches.3.0.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.branches.3.0.conv2.weight from pretrained model\n",
            "=> loading stage4.0.branches.3.0.bn2.weight from pretrained model\n",
            "=> loading stage4.0.branches.3.0.bn2.bias from pretrained model\n",
            "=> loading stage4.0.branches.3.0.bn2.running_mean from pretrained model\n",
            "=> loading stage4.0.branches.3.0.bn2.running_var from pretrained model\n",
            "=> loading stage4.0.branches.3.0.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.branches.3.1.conv1.weight from pretrained model\n",
            "=> loading stage4.0.branches.3.1.bn1.weight from pretrained model\n",
            "=> loading stage4.0.branches.3.1.bn1.bias from pretrained model\n",
            "=> loading stage4.0.branches.3.1.bn1.running_mean from pretrained model\n",
            "=> loading stage4.0.branches.3.1.bn1.running_var from pretrained model\n",
            "=> loading stage4.0.branches.3.1.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.branches.3.1.conv2.weight from pretrained model\n",
            "=> loading stage4.0.branches.3.1.bn2.weight from pretrained model\n",
            "=> loading stage4.0.branches.3.1.bn2.bias from pretrained model\n",
            "=> loading stage4.0.branches.3.1.bn2.running_mean from pretrained model\n",
            "=> loading stage4.0.branches.3.1.bn2.running_var from pretrained model\n",
            "=> loading stage4.0.branches.3.1.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.fuse_layers.0.1.0.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.0.1.1.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.0.1.1.bias from pretrained model\n",
            "=> loading stage4.0.fuse_layers.0.1.1.running_mean from pretrained model\n",
            "=> loading stage4.0.fuse_layers.0.1.1.running_var from pretrained model\n",
            "=> loading stage4.0.fuse_layers.0.1.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.fuse_layers.0.2.0.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.0.2.1.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.0.2.1.bias from pretrained model\n",
            "=> loading stage4.0.fuse_layers.0.2.1.running_mean from pretrained model\n",
            "=> loading stage4.0.fuse_layers.0.2.1.running_var from pretrained model\n",
            "=> loading stage4.0.fuse_layers.0.2.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.fuse_layers.0.3.0.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.0.3.1.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.0.3.1.bias from pretrained model\n",
            "=> loading stage4.0.fuse_layers.0.3.1.running_mean from pretrained model\n",
            "=> loading stage4.0.fuse_layers.0.3.1.running_var from pretrained model\n",
            "=> loading stage4.0.fuse_layers.0.3.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.fuse_layers.1.0.0.0.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.1.0.0.1.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.1.0.0.1.bias from pretrained model\n",
            "=> loading stage4.0.fuse_layers.1.0.0.1.running_mean from pretrained model\n",
            "=> loading stage4.0.fuse_layers.1.0.0.1.running_var from pretrained model\n",
            "=> loading stage4.0.fuse_layers.1.0.0.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.fuse_layers.1.2.0.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.1.2.1.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.1.2.1.bias from pretrained model\n",
            "=> loading stage4.0.fuse_layers.1.2.1.running_mean from pretrained model\n",
            "=> loading stage4.0.fuse_layers.1.2.1.running_var from pretrained model\n",
            "=> loading stage4.0.fuse_layers.1.2.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.fuse_layers.1.3.0.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.1.3.1.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.1.3.1.bias from pretrained model\n",
            "=> loading stage4.0.fuse_layers.1.3.1.running_mean from pretrained model\n",
            "=> loading stage4.0.fuse_layers.1.3.1.running_var from pretrained model\n",
            "=> loading stage4.0.fuse_layers.1.3.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.fuse_layers.2.0.0.0.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.2.0.0.1.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.2.0.0.1.bias from pretrained model\n",
            "=> loading stage4.0.fuse_layers.2.0.0.1.running_mean from pretrained model\n",
            "=> loading stage4.0.fuse_layers.2.0.0.1.running_var from pretrained model\n",
            "=> loading stage4.0.fuse_layers.2.0.0.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.fuse_layers.2.0.1.0.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.2.0.1.1.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.2.0.1.1.bias from pretrained model\n",
            "=> loading stage4.0.fuse_layers.2.0.1.1.running_mean from pretrained model\n",
            "=> loading stage4.0.fuse_layers.2.0.1.1.running_var from pretrained model\n",
            "=> loading stage4.0.fuse_layers.2.0.1.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.fuse_layers.2.1.0.0.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.2.1.0.1.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.2.1.0.1.bias from pretrained model\n",
            "=> loading stage4.0.fuse_layers.2.1.0.1.running_mean from pretrained model\n",
            "=> loading stage4.0.fuse_layers.2.1.0.1.running_var from pretrained model\n",
            "=> loading stage4.0.fuse_layers.2.1.0.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.fuse_layers.2.3.0.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.2.3.1.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.2.3.1.bias from pretrained model\n",
            "=> loading stage4.0.fuse_layers.2.3.1.running_mean from pretrained model\n",
            "=> loading stage4.0.fuse_layers.2.3.1.running_var from pretrained model\n",
            "=> loading stage4.0.fuse_layers.2.3.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.0.0.0.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.0.0.1.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.0.0.1.bias from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.0.0.1.running_mean from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.0.0.1.running_var from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.0.0.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.0.1.0.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.0.1.1.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.0.1.1.bias from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.0.1.1.running_mean from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.0.1.1.running_var from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.0.1.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.0.2.0.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.0.2.1.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.0.2.1.bias from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.0.2.1.running_mean from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.0.2.1.running_var from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.0.2.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.1.0.0.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.1.0.1.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.1.0.1.bias from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.1.0.1.running_mean from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.1.0.1.running_var from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.1.0.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.1.1.0.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.1.1.1.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.1.1.1.bias from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.1.1.1.running_mean from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.1.1.1.running_var from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.1.1.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.2.0.0.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.2.0.1.weight from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.2.0.1.bias from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.2.0.1.running_mean from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.2.0.1.running_var from pretrained model\n",
            "=> loading stage4.0.fuse_layers.3.2.0.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.branches.0.0.conv1.weight from pretrained model\n",
            "=> loading stage4.1.branches.0.0.bn1.weight from pretrained model\n",
            "=> loading stage4.1.branches.0.0.bn1.bias from pretrained model\n",
            "=> loading stage4.1.branches.0.0.bn1.running_mean from pretrained model\n",
            "=> loading stage4.1.branches.0.0.bn1.running_var from pretrained model\n",
            "=> loading stage4.1.branches.0.0.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.branches.0.0.conv2.weight from pretrained model\n",
            "=> loading stage4.1.branches.0.0.bn2.weight from pretrained model\n",
            "=> loading stage4.1.branches.0.0.bn2.bias from pretrained model\n",
            "=> loading stage4.1.branches.0.0.bn2.running_mean from pretrained model\n",
            "=> loading stage4.1.branches.0.0.bn2.running_var from pretrained model\n",
            "=> loading stage4.1.branches.0.0.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.branches.0.1.conv1.weight from pretrained model\n",
            "=> loading stage4.1.branches.0.1.bn1.weight from pretrained model\n",
            "=> loading stage4.1.branches.0.1.bn1.bias from pretrained model\n",
            "=> loading stage4.1.branches.0.1.bn1.running_mean from pretrained model\n",
            "=> loading stage4.1.branches.0.1.bn1.running_var from pretrained model\n",
            "=> loading stage4.1.branches.0.1.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.branches.0.1.conv2.weight from pretrained model\n",
            "=> loading stage4.1.branches.0.1.bn2.weight from pretrained model\n",
            "=> loading stage4.1.branches.0.1.bn2.bias from pretrained model\n",
            "=> loading stage4.1.branches.0.1.bn2.running_mean from pretrained model\n",
            "=> loading stage4.1.branches.0.1.bn2.running_var from pretrained model\n",
            "=> loading stage4.1.branches.0.1.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.branches.1.0.conv1.weight from pretrained model\n",
            "=> loading stage4.1.branches.1.0.bn1.weight from pretrained model\n",
            "=> loading stage4.1.branches.1.0.bn1.bias from pretrained model\n",
            "=> loading stage4.1.branches.1.0.bn1.running_mean from pretrained model\n",
            "=> loading stage4.1.branches.1.0.bn1.running_var from pretrained model\n",
            "=> loading stage4.1.branches.1.0.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.branches.1.0.conv2.weight from pretrained model\n",
            "=> loading stage4.1.branches.1.0.bn2.weight from pretrained model\n",
            "=> loading stage4.1.branches.1.0.bn2.bias from pretrained model\n",
            "=> loading stage4.1.branches.1.0.bn2.running_mean from pretrained model\n",
            "=> loading stage4.1.branches.1.0.bn2.running_var from pretrained model\n",
            "=> loading stage4.1.branches.1.0.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.branches.1.1.conv1.weight from pretrained model\n",
            "=> loading stage4.1.branches.1.1.bn1.weight from pretrained model\n",
            "=> loading stage4.1.branches.1.1.bn1.bias from pretrained model\n",
            "=> loading stage4.1.branches.1.1.bn1.running_mean from pretrained model\n",
            "=> loading stage4.1.branches.1.1.bn1.running_var from pretrained model\n",
            "=> loading stage4.1.branches.1.1.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.branches.1.1.conv2.weight from pretrained model\n",
            "=> loading stage4.1.branches.1.1.bn2.weight from pretrained model\n",
            "=> loading stage4.1.branches.1.1.bn2.bias from pretrained model\n",
            "=> loading stage4.1.branches.1.1.bn2.running_mean from pretrained model\n",
            "=> loading stage4.1.branches.1.1.bn2.running_var from pretrained model\n",
            "=> loading stage4.1.branches.1.1.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.branches.2.0.conv1.weight from pretrained model\n",
            "=> loading stage4.1.branches.2.0.bn1.weight from pretrained model\n",
            "=> loading stage4.1.branches.2.0.bn1.bias from pretrained model\n",
            "=> loading stage4.1.branches.2.0.bn1.running_mean from pretrained model\n",
            "=> loading stage4.1.branches.2.0.bn1.running_var from pretrained model\n",
            "=> loading stage4.1.branches.2.0.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.branches.2.0.conv2.weight from pretrained model\n",
            "=> loading stage4.1.branches.2.0.bn2.weight from pretrained model\n",
            "=> loading stage4.1.branches.2.0.bn2.bias from pretrained model\n",
            "=> loading stage4.1.branches.2.0.bn2.running_mean from pretrained model\n",
            "=> loading stage4.1.branches.2.0.bn2.running_var from pretrained model\n",
            "=> loading stage4.1.branches.2.0.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.branches.2.1.conv1.weight from pretrained model\n",
            "=> loading stage4.1.branches.2.1.bn1.weight from pretrained model\n",
            "=> loading stage4.1.branches.2.1.bn1.bias from pretrained model\n",
            "=> loading stage4.1.branches.2.1.bn1.running_mean from pretrained model\n",
            "=> loading stage4.1.branches.2.1.bn1.running_var from pretrained model\n",
            "=> loading stage4.1.branches.2.1.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.branches.2.1.conv2.weight from pretrained model\n",
            "=> loading stage4.1.branches.2.1.bn2.weight from pretrained model\n",
            "=> loading stage4.1.branches.2.1.bn2.bias from pretrained model\n",
            "=> loading stage4.1.branches.2.1.bn2.running_mean from pretrained model\n",
            "=> loading stage4.1.branches.2.1.bn2.running_var from pretrained model\n",
            "=> loading stage4.1.branches.2.1.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.branches.3.0.conv1.weight from pretrained model\n",
            "=> loading stage4.1.branches.3.0.bn1.weight from pretrained model\n",
            "=> loading stage4.1.branches.3.0.bn1.bias from pretrained model\n",
            "=> loading stage4.1.branches.3.0.bn1.running_mean from pretrained model\n",
            "=> loading stage4.1.branches.3.0.bn1.running_var from pretrained model\n",
            "=> loading stage4.1.branches.3.0.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.branches.3.0.conv2.weight from pretrained model\n",
            "=> loading stage4.1.branches.3.0.bn2.weight from pretrained model\n",
            "=> loading stage4.1.branches.3.0.bn2.bias from pretrained model\n",
            "=> loading stage4.1.branches.3.0.bn2.running_mean from pretrained model\n",
            "=> loading stage4.1.branches.3.0.bn2.running_var from pretrained model\n",
            "=> loading stage4.1.branches.3.0.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.branches.3.1.conv1.weight from pretrained model\n",
            "=> loading stage4.1.branches.3.1.bn1.weight from pretrained model\n",
            "=> loading stage4.1.branches.3.1.bn1.bias from pretrained model\n",
            "=> loading stage4.1.branches.3.1.bn1.running_mean from pretrained model\n",
            "=> loading stage4.1.branches.3.1.bn1.running_var from pretrained model\n",
            "=> loading stage4.1.branches.3.1.bn1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.branches.3.1.conv2.weight from pretrained model\n",
            "=> loading stage4.1.branches.3.1.bn2.weight from pretrained model\n",
            "=> loading stage4.1.branches.3.1.bn2.bias from pretrained model\n",
            "=> loading stage4.1.branches.3.1.bn2.running_mean from pretrained model\n",
            "=> loading stage4.1.branches.3.1.bn2.running_var from pretrained model\n",
            "=> loading stage4.1.branches.3.1.bn2.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.fuse_layers.0.1.0.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.0.1.1.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.0.1.1.bias from pretrained model\n",
            "=> loading stage4.1.fuse_layers.0.1.1.running_mean from pretrained model\n",
            "=> loading stage4.1.fuse_layers.0.1.1.running_var from pretrained model\n",
            "=> loading stage4.1.fuse_layers.0.1.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.fuse_layers.0.2.0.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.0.2.1.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.0.2.1.bias from pretrained model\n",
            "=> loading stage4.1.fuse_layers.0.2.1.running_mean from pretrained model\n",
            "=> loading stage4.1.fuse_layers.0.2.1.running_var from pretrained model\n",
            "=> loading stage4.1.fuse_layers.0.2.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.fuse_layers.0.3.0.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.0.3.1.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.0.3.1.bias from pretrained model\n",
            "=> loading stage4.1.fuse_layers.0.3.1.running_mean from pretrained model\n",
            "=> loading stage4.1.fuse_layers.0.3.1.running_var from pretrained model\n",
            "=> loading stage4.1.fuse_layers.0.3.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.fuse_layers.1.0.0.0.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.1.0.0.1.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.1.0.0.1.bias from pretrained model\n",
            "=> loading stage4.1.fuse_layers.1.0.0.1.running_mean from pretrained model\n",
            "=> loading stage4.1.fuse_layers.1.0.0.1.running_var from pretrained model\n",
            "=> loading stage4.1.fuse_layers.1.0.0.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.fuse_layers.1.2.0.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.1.2.1.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.1.2.1.bias from pretrained model\n",
            "=> loading stage4.1.fuse_layers.1.2.1.running_mean from pretrained model\n",
            "=> loading stage4.1.fuse_layers.1.2.1.running_var from pretrained model\n",
            "=> loading stage4.1.fuse_layers.1.2.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.fuse_layers.1.3.0.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.1.3.1.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.1.3.1.bias from pretrained model\n",
            "=> loading stage4.1.fuse_layers.1.3.1.running_mean from pretrained model\n",
            "=> loading stage4.1.fuse_layers.1.3.1.running_var from pretrained model\n",
            "=> loading stage4.1.fuse_layers.1.3.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.fuse_layers.2.0.0.0.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.2.0.0.1.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.2.0.0.1.bias from pretrained model\n",
            "=> loading stage4.1.fuse_layers.2.0.0.1.running_mean from pretrained model\n",
            "=> loading stage4.1.fuse_layers.2.0.0.1.running_var from pretrained model\n",
            "=> loading stage4.1.fuse_layers.2.0.0.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.fuse_layers.2.0.1.0.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.2.0.1.1.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.2.0.1.1.bias from pretrained model\n",
            "=> loading stage4.1.fuse_layers.2.0.1.1.running_mean from pretrained model\n",
            "=> loading stage4.1.fuse_layers.2.0.1.1.running_var from pretrained model\n",
            "=> loading stage4.1.fuse_layers.2.0.1.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.fuse_layers.2.1.0.0.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.2.1.0.1.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.2.1.0.1.bias from pretrained model\n",
            "=> loading stage4.1.fuse_layers.2.1.0.1.running_mean from pretrained model\n",
            "=> loading stage4.1.fuse_layers.2.1.0.1.running_var from pretrained model\n",
            "=> loading stage4.1.fuse_layers.2.1.0.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.fuse_layers.2.3.0.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.2.3.1.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.2.3.1.bias from pretrained model\n",
            "=> loading stage4.1.fuse_layers.2.3.1.running_mean from pretrained model\n",
            "=> loading stage4.1.fuse_layers.2.3.1.running_var from pretrained model\n",
            "=> loading stage4.1.fuse_layers.2.3.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.0.0.0.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.0.0.1.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.0.0.1.bias from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.0.0.1.running_mean from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.0.0.1.running_var from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.0.0.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.0.1.0.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.0.1.1.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.0.1.1.bias from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.0.1.1.running_mean from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.0.1.1.running_var from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.0.1.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.0.2.0.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.0.2.1.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.0.2.1.bias from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.0.2.1.running_mean from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.0.2.1.running_var from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.0.2.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.1.0.0.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.1.0.1.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.1.0.1.bias from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.1.0.1.running_mean from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.1.0.1.running_var from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.1.0.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.1.1.0.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.1.1.1.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.1.1.1.bias from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.1.1.1.running_mean from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.1.1.1.running_var from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.1.1.1.num_batches_tracked from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.2.0.0.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.2.0.1.weight from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.2.0.1.bias from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.2.0.1.running_mean from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.2.0.1.running_var from pretrained model\n",
            "=> loading stage4.1.fuse_layers.3.2.0.1.num_batches_tracked from pretrained model\n",
            "=> loading last_layer.0.weight from pretrained model\n",
            "=> loading last_layer.0.bias from pretrained model\n",
            "=> loading last_layer.1.weight from pretrained model\n",
            "=> loading last_layer.1.bias from pretrained model\n",
            "=> loading last_layer.1.running_mean from pretrained model\n",
            "=> loading last_layer.1.running_var from pretrained model\n",
            "=> loading last_layer.1.num_batches_tracked from pretrained model\n",
            "=> loading last_layer.3.weight from pretrained model\n",
            "=> loading last_layer.3.bias from pretrained model\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "  0% 0/150 [00:00<?, ?it/s]processing: 0 images\n",
            "mIoU: 0.1864\n",
            " 67% 100/150 [00:43<00:22,  2.19it/s]processing: 100 images\n",
            "mIoU: 0.1878\n",
            "100% 150/150 [01:02<00:00,  2.40it/s]\n",
            "MeanIU:  0.1910, Pixel_Acc:  0.9530,             Mean_Acc:  0.2003, Class IoU: \n",
            "[0.95325102 0.         0.00183753 0.         0.        ]\n",
            "Mins: 1\n",
            "Done\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}